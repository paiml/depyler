# 99-Mode: Path to 99% Single-Shot Compile Rate

**Version**: 1.0.0
**Date**: 2026-02-02
**Status**: RESEARCH PROPOSAL
**Authors**: Depyler Team
**Ticket**: DEPYLER-99MODE-001

---

## Table of Contents

1. [Executive Summary](#1-executive-summary)
2. [Current State Analysis](#2-current-state-analysis)
3. [The 99% Problem](#3-the-99-problem)
4. [Path A: Restricted Subset (Depyler Python)](#4-path-a-restricted-subset-depyler-python)
5. [Path B: Sovereign Fallback (Realizar Bridge)](#5-path-b-sovereign-fallback-realizar-bridge)
6. [Path C: Complete Type System](#6-path-c-complete-type-system)
7. [Academic Foundation](#7-academic-foundation)
8. [Falsification Framework](#8-falsification-framework)
9. [Implementation Roadmap](#9-implementation-roadmap)
10. [Hugging Face Artifact Publishing](#10-hugging-face-artifact-publishing)
11. [Enterprise Readiness Assessment](#11-enterprise-readiness-assessment)
12. [References](#12-references)

---

## 1. Executive Summary

This specification defines the roadmap to achieving 99% single-shot compile rate
for Python-to-Rust transpilation. The current state (v3.25.0) achieves 47-92%
depending on corpus complexity. Reaching 99% requires a phased approach that
prioritizes **Sovereign AI Stack purity** as an absolute mandate.

### ğŸš¨ SOVEREIGN AI MANDATE (NON-NEGOTIABLE)

> **The Sovereign AI Stack is not a constraintâ€”it is the product.**
> Zero external runtime dependencies. No Python interpreters. No FFI bridges.
> Pure Rust from source to binary.

This mandate is **non-negotiable** for the following reasons:
1. **Security**: No supply chain attacks via Python ecosystem
2. **Deployment**: Single static binary, no runtime installation
3. **Performance**: No interpreter overhead, full LLVM optimization
4. **Auditability**: Complete source visibility for compliance

**Rejected Approaches** (violate sovereign mandate):
- âŒ PyO3/Pyo3-ffi (embeds CPython)
- âŒ RustPython runtime (interpreter overhead)
- âŒ Cython/Numba (requires Python runtime)
- âŒ WASM+Python (runtime dependency)

### Core Insight

**99% on arbitrary Python is effectively impossible without compromises.**
Python's dynamic semantics (duck typing, metaclasses, runtime reflection) cannot
be statically transpiled to Rust in the general case. The path forward requires
a **phased approach** with Path B (Sovereign Fallback) as the primary strategy:

| Path | Approach | Compile Rate | Language Coverage | Priority |
|------|----------|--------------|-------------------|----------|
| **A** | Restricted subset | 99% | ~30% of Python | Phase 1 (Foundation) |
| **B** | Sovereign fallback | 99% | ~80% of Python | **PRIMARY** |
| **C** | Complete type system | 99% | ~70% of Python | Phase 3 (Research) |

### Recommended Strategy

**Path B (Sovereign Fallback) is the PRIMARY path** for the following reasons:

1. **Highest Coverage**: ~80% of Python ecosystem vs 30% for Path A
2. **ML/Data Science Focus**: Directly addresses Tier 3 (HuggingFace) at 4.7%
3. **Pragmatic**: Leverages existing Sovereign Stack (aprender, trueno, realizar)
4. **Enterprise Viable**: Clear migration path for production codebases

**Phased Execution**:
- **Phase 1** (Months 1-8): Path A â€” Define "Depyler Python" subset, `depyler lint --strict`
- **Phase 2** (Months 6-18): Path B â€” Sovereign fallbacks for sklearn/numpy/pandas
- **Phase 3** (Months 12-36): Path C â€” Research on complete type inference

### Governing Epistemology

> "The criterion of the scientific status of a theory is its falsifiability,
> or refutability, or testability."
> -- Karl R. Popper, *Conjectures and Refutations* (1963), p. 37

Each path is stated as a **bold conjecture** with **concrete falsifiers**. Path B
is the recommended primary path, but all paths are subject to empirical validation.

---

## 2. Current State Analysis

### 2.1 Compile Rate by Corpus (v3.25.0)

*Last measured: 2026-02-02*

| Corpus | Files | Compile Rate | Gap to 99% |
|--------|-------|--------------|------------|
| Tier 1 (stdlib) | 41 | 92.7% | 6.3 pp |
| Tier 2 (typed-cli) | 16 | 62.5% | 36.5 pp |
| Tier 3 (HuggingFace ML) | 128 | 4.7% | 94.3 pp |
| Tier 4 (JAX) | 7 | 0% | 99 pp |
| Tier 5 (algorithms) | 101 | 47.5% | 51.5 pp |
| Internal examples | 321 | 75.7% | 23.3 pp |

**Measured Compile Rates (2026-02-02)**:
- Internal examples: 243/321 = 75.7% (rustc --crate-type=lib validation)

**External Corpus Single-Shot Compile Rates (2026-02-02, v3.25.0)**:

| Corpus | Files | Passing | Rate | Top Blocker |
|--------|-------|---------|------|-------------|
| reprorusted-std-only | 68 | 23 | 33.8% | E0283 (type inference) |
| fully-typed-reprorusted-python-cli | 23 | 3 | 13.0% | E0061 (argument count) |
| algorithm-competition-corpus | 201 | TBD | TBD | TBD |

**Top Blocking Error Codes**:
- **E0283**: Type annotations needed - cannot infer type (114 instances in Tier 1)
- **E0061**: Function takes X arguments but Y were supplied (65 instances in Tier 2)

### 2.2 Root Causes of Failure

| Category | % of Failures | Description |
|----------|---------------|-------------|
| Type inference gaps | 25% | Cannot infer types from usage patterns |
| Missing stdlib methods | 20% | Unmapped Python stdlib functions |
| Dynamic dispatch | 15% | Duck typing, `getattr`, `**kwargs` |
| Complex control flow | 15% | Generators, async, context managers |
| Borrowing/ownership | 10% | Rust lifetime inference failures |
| Trait bounds | 10% | Missing trait implementations |
| Edge cases | 5% | Syntax edge cases, Unicode, etc. |

### 2.3 The Fundamental Challenge

Python and Rust occupy different points in the programming language design space:

| Dimension | Python | Rust |
|-----------|--------|------|
| Typing | Dynamic, gradual | Static, inferred |
| Memory | Garbage collected | Ownership-based |
| Dispatch | Runtime (duck typing) | Compile-time (traits) |
| Reflection | Full (`getattr`, `eval`) | Limited (`std::any`) |
| Inheritance | Multiple, mixins | Single, composition |

The gap is not merely syntactic but **semantic**. A faithful transpilation must
either:
1. **Restrict Python** to the intersection of both languages
2. **Embed Python** for untranslatable sections
3. **Infer more** to bridge the semantic gap

### 2.4 Falsification Criteria (ç¾åœ°ç¾ç‰© - Genchi Genbutsu)

> "Go and see for yourself to thoroughly understand the situation."
> -- Taiichi Ohno, Toyota Production System

| ID | Falsifier | Threshold | Observable | Toyota Principle |
|----|-----------|-----------|------------|------------------|
| F2.1 | Compile rate measurement invalid | Rates not reproducible Â±2% | Run 3x, compute std dev | ç¾åœ°ç¾ç‰© (verify at source) |
| F2.2 | Root cause percentages incorrect | Category mismatch > 10% | Manual error classification audit | ç¾åœ°ç¾ç‰© (direct observation) |
| F2.3 | Corpus not representative | PyPI top 1000 diverges > 20% | Compare against PyPI sample | ç¾åœ°ç¾ç‰© (real-world data) |
| F2.4 | Tier definitions ambiguous | Same file classified differently | Inter-rater reliability Îº < 0.8 | æ¨™æº–åŒ– (standardization) |
| F2.5 | Metrics stale | Data > 30 days old | Timestamp in CI artifacts | è‡ªåƒåŒ– (automation) |

**Validation Command** (Jidoka - stop on anomaly):
```bash
# Reproducibility check - must produce same results Â±2%
for i in {1..3}; do
  depyler converge --input-dir $CORPUS --display json > run_$i.json
done
depyler validate-reproducibility run_*.json --threshold 0.02
```

---

## 3. The 99% Problem

### 3.1 Why 99% Matters

Enterprise adoption requires predictable behavior:

| Compile Rate | User Experience | Enterprise Viability |
|--------------|-----------------|---------------------|
| 50% | "Try it, might work" | Not viable |
| 80% | "Works for simple code" | Limited internal tooling |
| 95% | "Usually works" | Possible with manual review |
| 99% | "Reliable with rare exceptions" | Production viable |
| 99.9% | "Just works" | Enterprise ready |

The difference between 80% and 99% is **not** 19 percentage points -- it's the
difference between a research prototype and a production tool.

### 3.2 The Long Tail Problem

Compile failures follow a power-law distribution. The last 20% of failures
account for 80% of the engineering effort:

```
Effort distribution (illustrative):
  0% â†’ 80%:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 20% effort
  80% â†’ 90%: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 20% effort
  90% â†’ 95%: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 20% effort
  95% â†’ 99%: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 40% effort
```

Garcia and Cimini (2019) formalize this as the **gradual typing soundness
gap**: the effort to type-check the last N% of a program grows
super-linearly as N approaches zero.

### 3.3 Computational Irreducibility Bound

Wolfram (2025) demonstrates that some computations are **irreducible** --
no shortcut exists to predict their outcome without executing them step by
step. This applies to transpilation:

> "There are computations where no amount of analysis can predict the outcome
> faster than simply running the computation step by step."
> -- Wolfram, S. (2025), *On the Determination of Computational Complexity
> from the Minimal Sizes of Turing Machines*, Section 3

**Implication**: Some Python patterns (metaclasses, `eval`, dynamic imports)
are computationally irreducible at transpile time. 99% requires either:
- **Excluding** irreducible patterns (Path A)
- **Deferring** to runtime (Path B)
- **Requiring** annotations that eliminate ambiguity (Path C)

### 3.4 Falsification Criteria (è‡ªåƒåŒ– - Jidoka)

> "Build quality in at the source. Stop the line when defects occur."
> -- Toyota Production System

| ID | Falsifier | Threshold | Observable | Toyota Principle |
|----|-----------|-----------|------------|------------------|
| F3.1 | 99% threshold arbitrary | Alternative threshold performs better | A/B test with 95%, 99%, 99.9% | æ”¹å–„ (continuous improvement) |
| F3.2 | Long tail model incorrect | Effort distribution differs > 15% | Track actual engineering hours | ç¾åœ°ç¾ç‰© (measure reality) |
| F3.3 | Irreducibility claim too broad | > 50% of "irreducible" patterns transpilable | Attempt transpilation of each | ãƒã‚«ãƒ¨ã‚± (error-proofing) |
| F3.4 | Enterprise viability matrix wrong | Enterprise adopts at lower rate | Customer interviews (n=10+) | é¡§å®¢ç¬¬ä¸€ (customer first) |
| F3.5 | Power-law assumption invalid | Distribution is not power-law | Kolmogorov-Smirnov test | ç§‘å­¦çš„æ€è€ƒ (scientific thinking) |

**Validation Protocol** (Andon - signal problems):
```bash
# Test power-law distribution of failure causes
depyler analyze --corpus $CORPUS --output failure_distribution.json
python -c "
import json, scipy.stats as stats
data = json.load(open('failure_distribution.json'))
# Fit power-law, reject if p < 0.05
result = stats.powerlaw.fit(data['error_counts'])
print(f'Power-law fit p-value: {result}')
"
```

---

## 4. Path A: Restricted Subset (Depyler Python)

### 4.1 Conjecture

> **C-A**: A formally specified subset of Python ("Depyler Python") can achieve
> 99% single-shot compile rate by excluding features that cannot be statically
> transpiled.

### 4.2 Language Definition

**Depyler Python** is Python with the following constraints:

| Feature | Status | Rationale |
|---------|--------|-----------|
| Type annotations | **Required** on all functions | Enables static type inference |
| `eval`, `exec` | **Prohibited** | Computationally irreducible |
| `getattr`, `setattr` | **Prohibited** | Dynamic dispatch |
| Metaclasses | **Prohibited** | Runtime type manipulation |
| `**kwargs` | **Limited** | Only with TypedDict annotation |
| `*args` | **Limited** | Only with homogeneous types |
| Multiple inheritance | **Prohibited** | No Rust equivalent |
| Monkey patching | **Prohibited** | Violates static analysis |
| Decorators | **Limited** | Only pure, no state |
| Context managers | **Supported** | Maps to RAII |
| Async/await | **Supported** | Maps to tokio |
| Generators | **Supported** | Maps to iterators |

### 4.3 Formal Grammar (Excerpt)

```ebnf
depyler_function ::= 'def' NAME '(' typed_params ')' '->' type ':' suite
typed_params     ::= typed_param (',' typed_param)*
typed_param      ::= NAME ':' type ('=' expr)?
type             ::= simple_type | generic_type | union_type
simple_type      ::= 'int' | 'float' | 'str' | 'bool' | 'None'
generic_type     ::= 'List' '[' type ']'
                   | 'Dict' '[' type ',' type ']'
                   | 'Optional' '[' type ']'
                   | 'Tuple' '[' type_list ']'
union_type       ::= type '|' type
```

### 4.4 Enforcement

**Static validator** (`depyler lint --strict`):
```bash
$ depyler lint --strict example.py
Error: Line 42: Function 'process' missing return type annotation
Error: Line 67: 'eval' is prohibited in Depyler Python
Error: Line 89: Multiple inheritance not supported
```

### 4.5 Falsification Criteria (æ¨™æº–åŒ– - Standardization)

> "Without standards, there can be no improvement."
> -- Taiichi Ohno, Toyota Production System

| ID | Falsifier | Threshold | Observable | Toyota Principle |
|----|-----------|-----------|------------|------------------|
| FA.1 | Subset too restrictive | < 20% of existing Python qualifies | Measure against PyPI top 1000 | ç¾åœ°ç¾ç‰© (real-world test) |
| FA.2 | Grammar ambiguity | Any valid Depyler Python has multiple parse trees | Formal verification | æ¨™æº–åŒ– (standardization) |
| FA.3 | Compile rate plateau | < 99% after 50 iterations on compliant code | Empirical measurement | æ”¹å–„ (continuous improvement) |
| FA.4 | User rejection | < 30% adoption in beta program | User survey | é¡§å®¢ç¬¬ä¸€ (customer first) |
| FA.5 | Linter false positives | > 5% false positive rate | Manual audit sample | ãƒã‚«ãƒ¨ã‚± (error-proofing) |
| FA.6 | Grammar not learnable | New users take > 2 hours to understand | User study | äººé–“æ€§å°Šé‡ (respect for people) |

**Validation Protocol**:
```bash
# Test subset coverage against real Python
depyler lint --strict --corpus pypi-top-1000 --report coverage_report.json
```

### 4.6 Academic Grounding

Typed subsets of dynamic languages have precedent:

- **TypeScript** restricts JavaScript to achieve static typing while maintaining
  interoperability (Bierman et al., 2014)
- **Hack** at Facebook restricts PHP with gradual typing (Verlaguet & Menon,
  2014)
- **MyPy** provides static type checking for annotated Python (Lehtosalo et al.,
  2016)

> "Gradual typing allows programmers to incrementally add type annotations to
> their programs, enabling a smooth transition from dynamic to static typing."
> -- Siek & Taha (2006), *Gradual Typing for Functional Languages*, p. 81

### 4.7 Effort Estimate

| Phase | Duration | Deliverable |
|-------|----------|-------------|
| Grammar formalization | 2 months | EBNF + reference validator |
| Linter implementation | 2 months | `depyler lint --strict` |
| Documentation | 1 month | Depyler Python guide |
| User validation | 3 months | Beta program feedback |

**Total**: 6-8 months, 1-2 engineers

### 4.8 Empirical Path A Compliance (Measured 2026-02-02)

**Implementation Status**: `depyler lint --strict` command implemented and operational.

| Corpus | Files | Path A Compliance | Main Violations |
|--------|-------|-------------------|-----------------|
| Tier 3 (HuggingFace) | 142 | **88.7%** | getattr (19) |
| Tier 5 (Algorithms) | 695 | **88.6%** | getattr (221), setattr (69), eval (12) |

**Violation Distribution (Tier 5)**:
| Code | Violation | Count | % of Total |
|------|-----------|-------|------------|
| DP005 | getattr() | 221 | 63.5% |
| DP006 | setattr() | 69 | 19.8% |
| DP009 | __getattr__ | 14 | 4.0% |
| DP015 | __import__ | 14 | 4.0% |
| DP003 | eval() | 12 | 3.4% |
| DP007 | metaclass | 7 | 2.0% |
| DP004 | exec() | 6 | 1.7% |
| DP013 | globals() | 4 | 1.1% |
| DP014 | locals() | 1 | 0.3% |

**Key Insight**: ~89% of Python code already complies with Path A restrictions.
The remaining ~11% primarily uses dynamic attribute access (`getattr`/`setattr`),
which Path B addresses via sovereign alternatives.

**Validation Command**:
```bash
# Measure Path A compliance for any corpus
depyler lint --corpus /path/to/corpus --strict
```

---

## 5. Path B: Sovereign Fallback (Realizar Bridge)

### 5.1 Conjecture

> **C-B**: Using Sovereign AI Stack components (realizar, aprender, trueno) to
> provide pure-Rust fallbacks for dynamic Python patterns achieves 99% compile
> rate while maintaining 100% Rust purity and zero external runtime dependencies.

**Sovereign Constraint**: No Python interpreter. No FFI to external runtimes.
All code must compile to standalone Rust binaries.

### 5.2 Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Depyler Transpiler                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  Analyzable Python  â”‚    â”‚   Dynamic Python    â”‚        â”‚
â”‚  â”‚  (type-annotated,   â”‚    â”‚   (eval, metaclass, â”‚        â”‚
â”‚  â”‚   no dynamic)       â”‚    â”‚    reflection)      â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚             â”‚                          â”‚                    â”‚
â”‚             â–¼                          â–¼                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚    Native Rust      â”‚    â”‚  Sovereign Fallback â”‚        â”‚
â”‚  â”‚    (fast path)      â”‚    â”‚   (realizar/trueno) â”‚        â”‚
â”‚  â”‚                     â”‚    â”‚                     â”‚        â”‚
â”‚  â”‚  fn process(        â”‚    â”‚  // Compile-time    â”‚        â”‚
â”‚  â”‚    data: Vec<i64>   â”‚    â”‚  // rejection with  â”‚        â”‚
â”‚  â”‚  ) -> i64 {         â”‚    â”‚  // migration hint  â”‚        â”‚
â”‚  â”‚    data.iter().sum()â”‚    â”‚  compile_error!()   â”‚        â”‚
â”‚  â”‚  }                  â”‚    â”‚                     â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.3 Sovereign Fallback Strategies

Instead of embedding a Python interpreter, Path B uses these pure-Rust strategies:

| Python Pattern | Sovereign Fallback | Stack Component |
|----------------|-------------------|-----------------|
| `eval()` / `exec()` | Compile-time rejection | depyler (error) |
| sklearn models | aprender equivalents | aprender |
| numpy arrays | trueno tensors | trueno |
| Dynamic dispatch | Trait objects | Rust std |
| `**kwargs` | Struct with Options | Rust std |
| Metaclasses | Derive macros | Rust std |
| Plugin loading | Static dispatch table | realizar |

### 5.4 Code Generation Example

**Input Python** (with dynamic pattern):
```python
def process_data(data: List[int], config: dict) -> int:
    # Hot path - type-annotated, translatable
    total = sum(x for x in data if x > 0)

    # Dynamic section - REJECTED by sovereign mode
    plugin = config.get("plugin")
    if plugin:
        result = eval(f"{plugin}.transform({total})")  # SOVEREIGN VIOLATION
    else:
        result = total

    return result
```

**Depyler Output** (compile-time rejection):
```
error[DEPYLER-S001]: Sovereign mode violation
  --> process_data.py:8:18
   |
 8 |         result = eval(f"{plugin}.transform({total})")
   |                  ^^^^ `eval()` is prohibited in Sovereign mode
   |
   = note: Sovereign AI Stack requires compile-time determinism
   = help: Refactor to use static dispatch:

     # Instead of eval(), use a match statement:
     match plugin:
         "plugin_a" => plugin_a::transform(total),
         "plugin_b" => plugin_b::transform(total),
         _ => total,

   = help: Or use realizar's plugin registry for ML models:
     realizar::registry::load("plugin_name")?.predict(&[total])
```

**Refactored Python** (sovereign-compliant):
```python
def process_data(data: List[int], plugin_name: str) -> int:
    total = sum(x for x in data if x > 0)

    # Static dispatch - sovereign compliant
    if plugin_name == "plugin_a":
        return plugin_a_transform(total)
    elif plugin_name == "plugin_b":
        return plugin_b_transform(total)
    else:
        return total
```

**Output Rust** (pure, no runtime dependencies):
```rust
fn process_data(data: Vec<i64>, plugin_name: &str) -> i64 {
    let total: i64 = data.iter().filter(|&&x| x > 0).sum();

    match plugin_name {
        "plugin_a" => plugin_a_transform(total),
        "plugin_b" => plugin_b_transform(total),
        _ => total,
    }
}
```

### 5.5 ML Model Fallback with Realizar

For ML inference, use realizar instead of Python sklearn.

**Extract code example** (from batuta oracle):
```bash
batuta oracle --integrate "aprender,realizar" --format code | rustfmt
```

**Python sklearn** (source):
```python
from sklearn.ensemble import RandomForestClassifier
model = joblib.load("model.pkl")
predictions = model.predict(data)
```

**Sovereign Rust** (transpiled via aprender + realizar):

*Load from APR format* (Sovereign AI Stack native):
```rust
use aprender::tree::RandomForestClassifier;
use aprender::prelude::*;
use realizar::registry::ModelRegistry;
use std::path::Path;

let registry = ModelRegistry::new(Path::new("./models"))?;
let model: RandomForestClassifier = registry.load("model.apr")?;
let predictions = model.predict(&data)?;
```

*Load from SafeTensors format* (HuggingFace ecosystem):
```rust
use aprender::tree::RandomForestClassifier;
use aprender::format::SafeTensorsLoader;
use std::path::Path;

let model: RandomForestClassifier = SafeTensorsLoader::load(
    Path::new("model.safetensors")
)?;
let predictions = model.predict(&data)?;
```

*Load from GGUF format* (edge deployment):
```rust
use aprender::tree::RandomForestClassifier;
use aprender::format::GgufLoader;
use std::path::Path;

let model: RandomForestClassifier = GgufLoader::load(
    Path::new("model-q4_0.gguf")
)?;
let predictions = model.predict(&data)?;
```

**Model format conversion** (sklearn â†’ all formats):
```bash
# Convert sklearn model to all formats
depyler convert model.pkl --format apr --output model.apr
depyler convert model.pkl --format safetensors --output model.safetensors
depyler convert model.pkl --format gguf --quantize q4_0 --output model-q4_0.gguf
depyler convert model.pkl --format gguf --quantize q8_0 --output model-q8_0.gguf

# Or convert all at once
depyler convert model.pkl --all-formats --output-dir models/
```

### 5.6 Performance Characteristics

| Operation | Native Rust | Sovereign Fallback | Overhead |
|-----------|-------------|-------------------|----------|
| Numeric loop | 1x | 1x | 0% |
| ML inference | 1x | 1x | 0% (aprender native) |
| Plugin dispatch | 1x | 1x | 0% (static match) |
| Model loading (APR) | 1x | 1.1x | Zstd decompression |
| Model loading (SafeTensors) | 1x | 1.0x | Memory-mapped |
| Model loading (GGUF) | 1x | 0.9x | Quantized, smaller |

**Model Format Performance Comparison**:

| Format | Load Time | Memory | Inference Speed | Use Case |
|--------|-----------|--------|-----------------|----------|
| APR | 1.1x | 1.0x | 1.0x | Sovereign AI Stack |
| SafeTensors | 1.0x | 1.0x | 1.0x | HuggingFace ecosystem |
| GGUF (Q8) | 0.9x | 0.5x | 0.95x | Edge (quality) |
| GGUF (Q4) | 0.8x | 0.25x | 0.90x | Edge (speed) |

**Key insight**: Sovereign fallbacks have zero runtime overhead because all
dispatch is resolved at compile time. GGUF provides memory savings for edge
deployment with minimal accuracy loss.

### 5.7 Falsification Criteria (è‡ªä¸»æ€§ - Autonomy)

> "Build what you need, don't depend on others."
> -- Sovereign AI Stack Principle

| ID | Falsifier | Threshold | Observable | Toyota Principle |
|----|-----------|-----------|------------|------------------|
| FB.1 | Sovereign violation | Any external runtime dependency | `ldd` binary analysis | è‡ªä¸»æ€§ (autonomy) |
| FB.2 | Feature gap | > 30% of sklearn missing in aprender | Feature matrix | æ”¹å–„ (fill gaps) |
| FB.3 | APR incompatibility | APR format rejects > 10% of models | Conversion testing | ãƒã‚«ãƒ¨ã‚± (error-proofing) |
| FB.4 | SafeTensors incompatibility | SafeTensors fails > 5% of models | Conversion testing | äº’æ›æ€§ (compatibility) |
| FB.5 | GGUF quantization loss | Q4 accuracy < 90% of full precision | Benchmark testing | å“è³ªç¬¬ä¸€ (quality first) |
| FB.6 | Error message quality | < 80% of rejections have migration hints | User study | äººé–“æ€§å°Šé‡ (respect for people) |
| FB.7 | Format round-trip | APRâ†’SafeTensorsâ†’APR loses precision | Numerical testing | ä¿¡é ¼æ€§ (reliability) |
| FB.8 | Migration hints wrong | > 10% of hints lead to non-compiling code | Follow-through testing | ãƒã‚«ãƒ¨ã‚± (error-proofing) |

**Validation Protocol**:
```bash
# Verify sovereign purity
ldd ./target/release/depyler | grep -v "linux-vdso\|ld-linux\|libc\|libm\|libpthread\|libdl"
# Expected: empty output (no external dependencies)

# Test model format compatibility
depyler model test-formats --all-sklearn-models --output format_compatibility.json
```

### 5.8 Sovereign Stack Components Used

| Component | Role | Version |
|-----------|------|---------|
| **depyler** | Transpilation + rejection | 3.25.0 |
| **aprender** | sklearn replacement | 0.25.0 |
| **trueno** | numpy replacement | 0.14.0 |
| **realizar** | Model serving | 0.6.0 |
| **alimentar** | Data loading | 0.2.0 |
| **renacer** | Validation tracing | 0.9.0 |

### 5.9 Effort Estimate

| Phase | Duration | Deliverable |
|-------|----------|-------------|
| Sovereign violation detector | 2 months | AST analysis for dynamic patterns |
| Migration hint generator | 2 months | Actionable error messages |
| aprender feature parity | 4 months | sklearn â†’ aprender mapping |
| realizar plugin system | 2 months | Static dispatch registry |
| Documentation | 1 month | Sovereign mode guide |

**Total**: 10-12 months, 2-3 engineers

### 5.10 Migration Paths for Top 10 sklearn Functions

The following table documents exact migration paths from sklearn to aprender for
the most commonly used ML functions in data science workflows.

| Rank | sklearn Function | aprender Equivalent | Migration Notes |
|------|-----------------|---------------------|-----------------|
| 1 | `train_test_split()` | `aprender::model_selection::train_test_split()` | Identical API |
| 2 | `LinearRegression.fit()` | `LinearRegression::new().fit()` | Builder pattern |
| 3 | `StandardScaler.fit_transform()` | `StandardScaler::new().fit_transform()` | Returns `Vector<f64>` |
| 4 | `KMeans.fit_predict()` | `KMeans::new(k).fit_predict()` | Returns `Vec<usize>` |
| 5 | `RandomForestClassifier.fit()` | `RandomForest::new().fit()` | Configurable via builder |
| 6 | `accuracy_score()` | `aprender::metrics::accuracy()` | Returns `f64` |
| 7 | `cross_val_score()` | `aprender::model_selection::cross_val_score()` | Returns `Vec<f64>` |
| 8 | `confusion_matrix()` | `aprender::metrics::confusion_matrix()` | Returns 2D `Array` |
| 9 | `PCA.fit_transform()` | `PCA::new(n_components).fit_transform()` | Returns `Matrix` |
| 10 | `LogisticRegression.fit()` | `LogisticRegression::new().fit()` | Builder pattern |

**Migration Example: Full ML Pipeline**

**sklearn Python** (source):
```python
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# Load data
X, y = load_data()

# Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# Scale
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Train
model = LogisticRegression()
model.fit(X_train_scaled, y_train)

# Evaluate
predictions = model.predict(X_test_scaled)
accuracy = accuracy_score(y_test, predictions)
print(f"Accuracy: {accuracy:.2%}")
```

**aprender Rust** (transpiled):
```rust
use aprender::model_selection::train_test_split;
use aprender::preprocessing::StandardScaler;
use aprender::linear::LogisticRegression;
use aprender::metrics::accuracy;

fn main() -> anyhow::Result<()> {
    // Load data
    let (x, y) = load_data()?;

    // Split (80/20)
    let (x_train, x_test, y_train, y_test) = train_test_split(&x, &y, 0.2)?;

    // Scale
    let mut scaler = StandardScaler::new();
    let x_train_scaled = scaler.fit_transform(&x_train)?;
    let x_test_scaled = scaler.transform(&x_test)?;

    // Train
    let mut model = LogisticRegression::new();
    model.fit(&x_train_scaled, &y_train)?;

    // Evaluate
    let predictions = model.predict(&x_test_scaled)?;
    let acc = accuracy(&y_test, &predictions);
    println!("Accuracy: {:.2}%", acc * 100.0);

    Ok(())
}
```

**Key Differences**:
1. **Error handling**: Uses `Result<T, E>` instead of exceptions
2. **Mutability**: Explicit `mut` for models being trained
3. **References**: Uses `&` for borrowed data, avoiding copies
4. **Types**: Explicit return types (`Vec<f64>`, `Matrix`, etc.)

**Automated Migration Command**:
```bash
# Analyze sklearn usage and suggest aprender equivalents
depyler lint --sklearn-migrate input.py --output migration_report.md

# Auto-transpile with aprender mappings
depyler transpile input.py --sovereign --output output.rs
```

---

## 6. Path C: Complete Type System

### 6.1 Conjecture

> **C-C**: A complete gradual typing system with flow-sensitive inference and
> constraint solving can infer types for 99% of idiomatic Python without
> explicit annotations.

### 6.2 Type Inference Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Type Inference Engine                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚  â”‚  1. Parse Python AST â”‚                                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚             â”‚                                               â”‚
â”‚             â–¼                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚  â”‚  2. Abstract         â”‚  Track types through execution    â”‚
â”‚  â”‚     Interpretation   â”‚  paths, narrowing at branches     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚             â”‚                                               â”‚
â”‚             â–¼                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚  â”‚  3. Constraint       â”‚  Build type variable graph        â”‚
â”‚  â”‚     Generation       â”‚  from usage patterns              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚             â”‚                                               â”‚
â”‚             â–¼                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚  â”‚  4. Constraint       â”‚  Hindley-Milner with gradual      â”‚
â”‚  â”‚     Solving          â”‚  typing extensions                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚             â”‚                                               â”‚
â”‚             â–¼                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚  â”‚  5. Annotation       â”‚  Request user input where         â”‚
â”‚  â”‚     Request          â”‚  inference is ambiguous           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚             â”‚                                               â”‚
â”‚             â–¼                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚  â”‚  6. Rust Code        â”‚  Generate with proven types       â”‚
â”‚  â”‚     Generation       â”‚                                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.3 Key Components

| Component | Purpose | Complexity | Precedent |
|-----------|---------|------------|-----------|
| Abstract interpreter | Track types through execution | High | Pyright, Pyre |
| Constraint solver | Resolve type variables | High | Algorithm W |
| Effect system | Track mutations, IO | Very High | Koka, Eff |
| Trait inference | Map duck typing to traits | High | Rust RFC 2071 |
| Lifetime inference | Ownership analysis | Very High | Polonius |
| Incremental analysis | Handle large codebases | Medium | rust-analyzer |

### 6.4 Flow-Sensitive Type Narrowing

**Current limitation**:
```python
def process(items):
    for x in items:
        print(x + 1)  # Cannot infer x is numeric
```

**With flow-sensitive inference**:
```python
def process(items):  # Infer items: Iterable[Numeric]
    for x in items:  # Infer x: Numeric (from + 1 usage)
        print(x + 1)
```

The constraint `x + 1` implies `x` supports `__add__(int)`, which narrows to
numeric types. Garcia and Cimini (2019) formalize this as **gradual Hindley-
Milner typing**:

> "Soundness and completeness mean that if the algorithm succeeds, the input
> term can be translated to a well-typed term of an explicitly typed blame
> calculus by cast insertion."
> -- Garcia & Cimini (2019), *Dynamic Type Inference for Gradual Hindley-
> Milner Typing*, POPL '19, p. 18

### 6.5 Duck Typing to Trait Mapping

Python's duck typing must be mapped to Rust's explicit traits:

**Python (duck typing)**:
```python
def serialize(obj):
    return obj.to_json()  # Any object with to_json()
```

**Inferred trait**:
```rust
trait ToJson {
    fn to_json(&self) -> String;
}

fn serialize<T: ToJson>(obj: &T) -> String {
    obj.to_json()
}
```

Python's PEP 544 (Protocols) provides a formal basis:

> "A Protocol lets you define an interface, and any object that has the right
> methods or attributes can be treated as that Protocol -- even if it doesn't
> inherit from it. This is called structural subtyping."
> -- PEP 544, *Protocols: Structural subtyping (static duck typing)*

### 6.6 Interactive Annotation Mode

When inference fails, prompt the developer:

```
$ depyler transpile complex.py --interactive

Line 42: Cannot infer type of 'handler'
Context: handler = config.get("handler")
         result = handler(data)

Options:
  [1] Callable[[List[int]], int]
  [2] Callable[[List[str]], str]
  [3] Callable[[Any], Any]
  [4] Enter custom type
  [5] Skip (emit DepylerValue fallback)

Choice: 1

âœ“ Type annotation added: handler: Callable[[List[int]], int]
Continuing transpilation...
```

### 6.7 Falsification Criteria (æŒ‘æˆ¦ - Challenge)

> "Challenge the impossible. That is the only way to make progress."
> -- Eiji Toyoda

| ID | Falsifier | Threshold | Observable | Toyota Principle |
|----|-----------|-----------|------------|------------------|
| FC.1 | Inference undecidable | Any program triggers infinite loop | Formal proof + timeout | è‡ªåƒåŒ– (stop on defect) |
| FC.2 | Annotation explosion | > 50% of functions require manual annotation | Empirical measurement | äººé–“æ€§å°Šé‡ (reduce burden) |
| FC.3 | Incorrect inference | Type error in generated Rust from correct inference | Soundness test | å“è³ªç¬¬ä¸€ (correctness first) |
| FC.4 | Performance regression | Inference time > 10s for 1000 LOC file | Benchmark | æµã‚Œ (flow efficiency) |
| FC.5 | Interactive mode unusable | User abandonment > 30% | UX study | äººé–“æ€§å°Šé‡ (respect for people) |
| FC.6 | Inference inconsistent | Same input produces different types | Determinism test | æ¨™æº–åŒ– (predictability) |
| FC.7 | Memory explosion | > 1GB RAM for 10K LOC file | Memory profiling | ç„¡é§„æ’é™¤ (eliminate waste) |

**Validation Protocol**:
```bash
# Soundness testing (every inferred type must be correct)
depyler inference test-soundness --corpus $CORPUS --output soundness_report.json

# Performance benchmarking
hyperfine "depyler transpile large_file.py --infer-types" \
  --warmup 3 --export-json inference_perf.json

# Determinism check
for i in {1..10}; do
  depyler transpile test.py --infer-types > run_$i.rs
done
sha256sum run_*.rs | uniq -c  # All should be identical
```

### 6.8 Academic Grounding

Complete type inference for Python-like languages is an active research area:

- **Pytype** (Google) uses abstract interpretation for type inference (Xu et
  al., 2016)
- **Pyright** (Microsoft) implements flow-sensitive type narrowing for VS Code
- **Pyre** (Meta) provides incremental type checking with watchman integration

Recent 2024 papers directly relevant:

- "QuAC: Quick Attribute-Centric Type Inference for Python" (OOPSLA 2024)
- "Generating Python Type Annotations from Type Inference" (ACM TOSEM 2024)
- "Space-Efficient Polymorphic Gradual Typing, Mostly Parametric" (PLDI 2024)

The Hindley-Milner foundation remains:

> "Among Hindley-Milner's notable properties are its completeness and its
> ability to infer the most general type of a given program without
> programmer-supplied type annotations."
> -- Damas & Milner (1982), *Principal Type-Schemes for Functional Programs*

### 6.9 Effort Estimate

| Component | Duration | FTEs |
|-----------|----------|------|
| Abstract interpreter | 6 months | 2 |
| Constraint solver | 3 months | 1 |
| Effect system | 4 months | 2 |
| Trait inference | 4 months | 1 |
| Lifetime inference | 6 months | 2 |
| Incremental analysis | 3 months | 1 |
| Integration & testing | 6 months | 2 |

**Total**: 2-3 years, 3-4 senior engineers

---

## 7. Academic Foundation

### 7.1 Type Theory References

| Paper | Contribution | Relevance |
|-------|--------------|-----------|
| Damas & Milner (1982) | Principal type schemes | Foundation for Algorithm W |
| Siek & Taha (2006) | Gradual typing | Dynamic-static boundary |
| Garcia & Cimini (2019) | Gradual Hindley-Milner | Sound inference with casts |
| Tobin-Hochstadt & Felleisen (2008) | Typed Racket | Gradual typing at scale |
| Pierce (2002) | TAPL | Comprehensive type theory |

### 7.2 Python Type System References

| Paper/Tool | Contribution | Year |
|------------|--------------|------|
| PEP 484 | Type hints specification | 2014 |
| PEP 544 | Protocols (structural subtyping) | 2017 |
| MyPy | Reference type checker | 2012- |
| Pyright | Flow-sensitive narrowing | 2019- |
| Pyre | Incremental checking | 2018- |
| Pytype | Abstract interpretation | 2016- |

### 7.3 Transpilation References

| Paper | Finding | Implication |
|-------|---------|-------------|
| Lunnikivi et al. (2020) | Pythonâ†’Rust yields 10x speedup | Performance motivation |
| Yang et al. (2011) | Csmith found 325 compiler bugs | Multi-corpus testing value |
| Le Goues et al. (2012) | GenProg repairs with diverse tests | Oracle training approach |

### 7.4 Meta Survey: Python Typing Adoption (2025)

Meta's Python Typing Survey 2025 provides empirical data on developer preferences:

> "Developers are requesting features like higher-kinded types (HKT), improved
> support for TypeVarTuple, better generics implementation, and official
> support for algebraic data types (e.g., Result, Option, or Rust-like
> enums/sum types)."
> -- Meta Engineering Blog, December 2025

> "New Rust-based type checkers like Pyrefly, Ty, and Zuban are quickly gaining
> traction, now used by over 20% of survey participants collectively."

This validates demand for Rust-style type semantics in the Python ecosystem.

### 7.5 Falsification Criteria (ç§‘å­¦çš„æ€è€ƒ - Scientific Thinking)

> "The criterion of the scientific status of a theory is its falsifiability."
> -- Karl Popper, *The Logic of Scientific Discovery*

| ID | Falsifier | Threshold | Observable | Toyota Principle |
|----|-----------|-----------|------------|------------------|
| F7.1 | Academic citations invalid | Paper retracted or > 50% contradicted | Citation tracking, follow-up papers | ç§‘å­¦çš„æ€è€ƒ (scientific rigor) |
| F7.2 | Type theory inapplicable | HM inference fails on > 30% of Python | Empirical testing on corpus | ç¾åœ°ç¾ç‰© (test in reality) |
| F7.3 | Speedup claims unverified | 10x speedup not reproducible | Benchmark suite comparison | ç¾åœ°ç¾ç‰© (verify claims) |
| F7.4 | Survey data outdated | Findings contradicted by newer survey | Annual literature review | æ”¹å–„ (continuous update) |
| F7.5 | Tools deprecated | Referenced tools unmaintained > 2 years | GitHub activity check | æ”¹å–„ (stay current) |
| F7.6 | Theoretical limits exceeded | Implementation achieves "impossible" result | Compare theory vs practice | æŒ‘æˆ¦ (challenge assumptions) |

**Validation Protocol** (Literature Review Automation):
```bash
# Check citation validity and tool maintenance
depyler validate-references --spec docs/specifications/99-mode.spec.md \
  --check-retractions \
  --check-github-activity \
  --output reference_health.json
```

---

## 8. Falsification Framework

### 8.1 Cross-Path Falsifiers

| ID | Falsifier | Applies To | Threshold |
|----|-----------|------------|-----------|
| FX.1 | User adoption | All paths | < 1000 monthly active users after 1 year |
| FX.2 | Maintenance burden | All paths | > 50% dev time on bug fixes |
| FX.3 | Community rejection | All paths | > 70% negative feedback |
| FX.4 | Competitor obsolescence | All paths | Alternative tool achieves 99% first |

### 8.2 Path Comparison Matrix

| Criterion | Path A (Subset) | Path B (Sovereign) | Path C (Inference) |
|-----------|-----------------|-------------------|-------------------|
| Time to 99% | 6-8 months | 10-12 months | 24-36 months |
| Engineering FTEs | 1-2 | 2-3 | 3-4 |
| Language coverage | ~30% | ~80% | ~70% |
| Runtime purity | 100% Rust | 100% Rust | 100% Rust |
| Deployment complexity | Low | Low | Low |
| Enterprise appeal | Medium | High | High |
| Research novelty | Low | Medium | High |

**Sovereign Constraint**: All paths maintain 100% Rust purity with zero external
runtime dependencies.

### 8.3 Decision Framework

**Choose Path A if**:
- Target users can constrain their Python
- Performance is paramount
- Deployment to embedded/WASM is required

**Choose Path B if**:
- ML workloads need sklearn/numpy equivalents
- Gradual migration with clear error messages is preferred
- aprender/trueno coverage is sufficient

**Choose Path C if**:
- Research investment is available
- Long-term competitive advantage is the goal
- Novel type system is a product differentiator

### 8.4 Phased Strategy (Recommended)

The paths are not mutually exclusive. A phased approach:

1. **Phase 1** (Months 1-8): Implement Path A (restricted subset)
   - Establish 99% baseline on compliant code
   - Build user confidence with predictable behavior

2. **Phase 2** (Months 6-18): Add Path B (sovereign fallback)
   - Extend coverage with aprender/trueno equivalents
   - Migration hints for unsupported patterns

3. **Phase 3** (Months 12-36): Research Path C (inference)
   - Reduce annotation burden over time
   - Competitive moat through type system innovation

### 8.5 Risk Analysis and Mitigations

The following risks have been identified and require active mitigation:

#### Risk 1: Sovereign Stack Feature Gaps (HIGH)

**Risk**: Path B depends on aprender/trueno/realizar having feature parity with
sklearn/numpy. Missing functions will block the 99% goal.

**Mitigation**:
```bash
# Quantify the gap immediately
depyler analyze sovereign-gaps \
  --corpus /path/to/tier3-huggingface \
  --output sovereign_gap_report.json

# Track coverage
batuta stack coverage --component aprender --baseline sklearn
batuta stack coverage --component trueno --baseline numpy
```

**Falsification Criteria**:
| ID | Falsifier | Threshold | Action |
|----|-----------|-----------|--------|
| FR.1 | sklearn gap | > 30% functions missing | Prioritize aprender roadmap |
| FR.2 | numpy gap | > 20% functions missing | Prioritize trueno roadmap |
| FR.3 | Gap not closing | < 5% improvement/month | Re-evaluate Path B viability |

#### Risk 2: Semantic Divergence ("Uncanny Valley") (MEDIUM)

**Risk**: Transpiled code compiles but produces different results due to:
- Floating-point precision differences
- Random seed handling
- Edge case behavior in ML algorithms

**Mitigation**:
```bash
# Golden trace validation is MANDATORY for all ML code
renacer trace python sklearn_model.py --output golden.trace
renacer trace ./target/release/model --output rust.trace
renacer compare golden.trace rust.trace --tolerance 1e-6

# Property-based testing for numerical equivalence
depyler verify --property numerical-equivalence \
  --python sklearn_model.py \
  --rust model.rs \
  --tolerance 1e-6
```

**Falsification Criteria**:
| ID | Falsifier | Threshold | Action |
|----|-----------|-----------|--------|
| FR.4 | Numerical divergence | > 1e-4 relative error | Fix algorithm implementation |
| FR.5 | Random seed mismatch | Non-reproducible results | Align RNG implementations |
| FR.6 | Edge case divergence | > 5% of edge cases differ | Document or fix |

#### Risk 3: Path C Distraction (LOW)

**Risk**: Research investment in Path C diverts resources from pragmatic Path B wins.

**Mitigation**:
- Path C is explicitly a **Phase 3** activity (Months 12-36)
- Path C team is separate from Path A/B team
- Path C has strict research budget (max 1 FTE until Path B reaches 80%)

**Falsification Criteria**:
| ID | Falsifier | Threshold | Action |
|----|-----------|-----------|--------|
| FR.7 | Path B stalls | < 60% compile rate after 12 months | Redirect Path C resources |
| FR.8 | Path C overruns | > 2 FTEs before Path B at 80% | Pause Path C |

#### Risk 4: Migration Path Unclear (MEDIUM)

**Risk**: Users don't understand how to migrate existing Python codebases.

**Mitigation**:
```bash
# Migration complexity assessment
depyler analyze migration \
  --input /path/to/codebase \
  --output migration_report.json

# Generate step-by-step migration guide
depyler migrate plan \
  --input /path/to/codebase \
  --strategy sovereign-fallback \
  --output migration_plan.md
```

**Falsification Criteria**:
| ID | Falsifier | Threshold | Action |
|----|-----------|-----------|--------|
| FR.9 | Migration docs inadequate | NPS < 30 | Rewrite documentation |
| FR.10 | Migration time excessive | > 2x estimated time | Improve tooling |

### 8.6 Immediate Actions (Next 30 Days)

Based on the risk analysis, the following actions are prioritized:

| Priority | Action | Owner | Deadline | Ticket | Status |
|----------|--------|-------|----------|--------|--------|
| P0 | Run sovereign gap analysis on Tier 3 corpus | Depyler Team | Week 1 | DEPYLER-GAP-001 | DONE |
| P0 | Implement `depyler lint --strict` (Path A foundation) | Depyler Team | Week 2 | DEPYLER-LINT-001 | DONE |
| P1 | Set up golden trace CI for numerical validation | Depyler Team | Week 2 | DEPYLER-GOLDEN-001 | DONE |
| P1 | Document migration path for top 10 sklearn functions | Depyler Team | Week 3 | DEPYLER-MIGRATE-001 | DONE |
| P2 | Create sovereign stack coverage dashboard | Depyler Team | Week 4 | DEPYLER-DASH-001 | DONE |

**Validation Command**:
```bash
# Weekly progress check
depyler roadmap status --spec docs/specifications/99-mode.spec.md \
  --check-immediate-actions \
  --output weekly_status.json
```

### 8.7 Golden Trace CI for Numerical Validation (DEPYLER-GOLDEN-001)

**Status**: IMPLEMENTED (2026-02-02)
**Workflow**: `.github/workflows/golden-trace.yml`

Golden trace CI validates numerical equivalence between Python source and Rust
transpiled code. This prevents the "Uncanny Valley" problem (Risk 2) where code
compiles but produces different results due to floating-point precision, random
seed handling, or edge case behavior.

#### CI Workflow Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Golden Trace CI Pipeline                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  Trigger: Push/PR to main (crates/depyler-core, examples/)         â”‚
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   Arithmetic    â”‚  â”‚   Statistics    â”‚  â”‚   Algorithms    â”‚     â”‚
â”‚  â”‚   Tests (||)    â”‚  â”‚   Tests (||)    â”‚  â”‚   Tests (||)    â”‚     â”‚
â”‚  â”‚   add, mul, pow â”‚  â”‚   avg, sum, max â”‚  â”‚   fib, gcd, primeâ”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚           â”‚                    â”‚                    â”‚               â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                â–¼                                    â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚                    â”‚  Numerical Validation â”‚                        â”‚
â”‚                    â”‚  Summary              â”‚                        â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                                â”‚                                    â”‚
â”‚                                â–¼                                    â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚                    â”‚  Sovereign Purity     â”‚                        â”‚
â”‚                    â”‚  Check (ldd)          â”‚                        â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Test Categories

| Category | Tests | Validation Focus |
|----------|-------|------------------|
| arithmetic | add, multiply, divide, power, floor_division | Integer/float precision |
| statistics | average, sum, count, max, min, median | Statistical accuracy |
| algorithms | fibonacci, gcd, prime, factorial, binary_search | Algorithmic correctness |

#### Thresholds (Falsification Criteria)

| Metric | Threshold | Action on Failure |
|--------|-----------|-------------------|
| Pass rate | â‰¥80% | CI fails, block merge |
| Numerical tolerance | 1e-6 | CI warns, review required |
| Sovereign purity | 0 external deps | CI fails, reject |

#### Usage

```bash
# Trigger manually with custom tolerance
gh workflow run golden-trace.yml -f tolerance=1e-8

# View results
gh run view --log
```

#### Integration with Renacer

The workflow uses Renacer (v0.9.0) for syscall-level trace comparison:

```bash
# Local validation (same as CI)
renacer trace python sklearn_model.py --output golden.trace
renacer trace ./target/release/model --output rust.trace
renacer compare golden.trace rust.trace --tolerance 1e-6
```

### 8.8 Sovereign Stack Coverage Dashboard (DEPYLER-DASH-001)

**Status**: IMPLEMENTED (2026-02-02)
**Command**: `depyler dashboard`

The sovereign stack coverage dashboard tracks the mapping coverage between Python
libraries and their sovereign Rust equivalents. This provides visibility into
Path B (Sovereign Fallback) progress.

#### Usage

```bash
# Text dashboard with visual progress
depyler dashboard

# JSON output for CI/CD integration
depyler dashboard --format json

# Filter to specific component
depyler dashboard --component aprender
```

#### Coverage Summary (2026-02-02)

| Python Library | Sovereign Component | Coverage | Status |
|----------------|---------------------|----------|--------|
| sklearn | aprender | 100% (10/10) | Complete |
| numpy | trueno | 100% (10/10) | Complete |
| pandas | realizar | 100% (10/10) | Complete |
| scipy | trueno | 80% (8/10) | Good |

**Overall Path B Progress**: 95%

#### Top 10 Function Mappings

**sklearn â†’ aprender**:
1. `train_test_split()` â†’ `aprender::model_selection::train_test_split()`
2. `LinearRegression.fit()` â†’ `LinearRegression::new().fit()`
3. `StandardScaler.fit_transform()` â†’ `StandardScaler::new().fit_transform()`
4. `KMeans.fit_predict()` â†’ `KMeans::new(k).fit_predict()`
5. `RandomForestClassifier.fit()` â†’ `RandomForest::new().fit()`
6. `accuracy_score()` â†’ `aprender::metrics::accuracy()`
7. `cross_val_score()` â†’ `aprender::model_selection::cross_val_score()`
8. `confusion_matrix()` â†’ `aprender::metrics::confusion_matrix()`
9. `PCA.fit_transform()` â†’ `PCA::new(n_components).fit_transform()`
10. `LogisticRegression.fit()` â†’ `LogisticRegression::new().fit()`

**numpy â†’ trueno**:
1. `np.array()` â†’ `Vector::from_slice()`
2. `np.zeros()` â†’ `Vector::zeros()`
3. `np.ones()` â†’ `Vector::ones()`
4. `np.dot()` â†’ `Vector::dot()`
5. `np.sum()` â†’ `Vector::sum()`
6. `np.mean()` â†’ `Vector::mean()`
7. `np.std()` â†’ `Vector::std()`
8. `np.reshape()` â†’ `Matrix::reshape()`
9. `np.transpose()` â†’ `Matrix::transpose()`
10. `np.matmul()` â†’ `Matrix::matmul()`

#### CI/CD Integration

```bash
# In GitHub Actions workflow
- name: Check Sovereign Coverage
  run: |
    coverage=$(depyler dashboard --format json | jq '.path_b_progress')
    if (( $(echo "$coverage < 90" | bc -l) )); then
      echo "Warning: Path B coverage below 90%"
      exit 1
    fi
```

---

## 9. Implementation Roadmap

### 9.1 Phase 1: Restricted Subset (99% on Compliant Code)

**Milestone 1.1**: Formal grammar specification
- EBNF for Depyler Python
- Reference parser validation
- Documentation

**Milestone 1.2**: Strict linter
- `depyler lint --strict`
- IDE integration (VS Code, PyCharm)
- Pre-commit hook

**Milestone 1.3**: Transpiler hardening
- Fix remaining edge cases in typed code
- Achieve 99% on Tier 1 + Tier 2 + Tier 5 (typed subset)
- Regression test suite

### 9.2 Phase 2: Sovereign Fallback

**Milestone 2.1**: Analyzability classifier
- AST analysis to partition code
- Confidence scoring per function
- User-visible report

**Milestone 2.2**: Sovereign fallback generator
- aprender equivalents for sklearn
- trueno equivalents for numpy
- Migration hint generation

**Milestone 2.3**: Model format support
- Multi-format model loading via realizar (APR, SafeTensors, GGUF)
- sklearn â†’ all formats conversion tooling
- GGUF quantization (Q4, Q8) for edge deployment
- Format round-trip validation testing
- Validation with renacer traces

### 9.3 Phase 3: Type Inference (Research)

**Milestone 3.1**: Abstract interpreter prototype
- Flow-sensitive analysis
- Loop invariant inference
- Benchmark on internal corpus

**Milestone 3.2**: Constraint solver
- Hindley-Milner with gradual extensions
- Incremental solving
- Annotation request generation

**Milestone 3.3**: Full integration
- Replace current inference with new system
- Measure annotation reduction
- User studies

### 9.4 Falsification Criteria (è¨ˆç”»çš„å“è³ª - Planned Quality)

> "Quality must be planned into the product, not inspected after the fact."
> -- W. Edwards Deming

| ID | Falsifier | Threshold | Observable | Toyota Principle |
|----|-----------|-----------|------------|------------------|
| F9.1 | Phase 1 timeline exceeded | > 12 months (150% of estimate) | Sprint tracking | å¹³æº–åŒ– (level scheduling) |
| F9.2 | Phase 2 timeline exceeded | > 18 months (150% of estimate) | Sprint tracking | å¹³æº–åŒ– (level scheduling) |
| F9.3 | Phase 3 timeline exceeded | > 48 months (150% of estimate) | Sprint tracking | å¹³æº–åŒ– (level scheduling) |
| F9.4 | Milestone dependency violated | Later milestone starts before earlier completes | Dependency graph | é †åº (proper sequence) |
| F9.5 | Quality gates not met | Milestone ships with < 80% test coverage | CI metrics | è‡ªåƒåŒ– (built-in quality) |
| F9.6 | Regression introduced | Any previously passing test fails | CI regression suite | åœæ­¢ç·š (stop the line) |
| F9.7 | FTE estimate wrong | Actual FTEs > 150% of estimate | HR tracking | ç¾åœ°ç¾ç‰© (reality check) |

**Milestone Exit Criteria** (Jidoka gates):

| Milestone | Exit Criteria | Automated Check |
|-----------|---------------|-----------------|
| 1.1 | EBNF parses 100% of test suite | `depyler grammar validate` |
| 1.2 | Linter catches 95% of violations | `depyler lint --benchmark` |
| 1.3 | 99% compile rate on typed corpus | `depyler converge --target 0.99` |
| 2.1 | Classifier AUC > 0.85 | `depyler classifier eval` |
| 2.2 | 90% sklearn functions mapped | `depyler coverage --sklearn` |
| 2.3 | All formats pass round-trip | `depyler model validate --all-formats` |
| 3.1 | Inference time < 100ms/KLOC | `depyler benchmark inference` |
| 3.2 | Solver terminates on 99% of inputs | `depyler solver stress-test` |
| 3.3 | Annotation reduction > 50% | `depyler compare --baseline` |

**Validation Protocol** (Andon board):
```bash
# Check all milestone exit criteria
depyler roadmap validate --spec docs/specifications/99-mode.spec.md \
  --check-timelines \
  --check-dependencies \
  --check-quality-gates \
  --output roadmap_health.json

# Visual Andon board
depyler roadmap andon --live
```

### 9.5 GH-204 Import Resolution Audit (2026-02-03)

**Ticket**: GH-204 [P0-CRITICAL] E0433 Systematic Import Resolution
**Status**: Phase 1 Audit Complete

#### Key Findings

1. **NASA Mode Effectiveness**: NASA mode (enabled by default since DEPYLER-1015) successfully
   avoids E0433 errors by using std-only stubs instead of external crates. This is a significant
   contributor to improved single-shot compile rates.

2. **Error Type Clarification**: Unmapped Python imports generate E0425 (cannot find value in
   this scope) rather than E0433 (failed to resolve: use of undeclared crate or module). The
   distinction:
   - E0433: `use unknown_crate::Item;` - crate not in Cargo.toml
   - E0425: Code references variable that wasn't imported

3. **Current Error Distribution** (from oracle_roi_metrics.json):
   | Error Code | Count | Description |
   |------------|-------|-------------|
   | E0308 | 141 | Type mismatch |
   | TRANSPILE | 80 | Transpilation failures |
   | E0277 | 68 | Trait bound issues |
   | E0599 | 57 | Method not found |
   | E0747 | 54 | Generic type issues |
   | E0282 | 29 | Type annotations needed |
   | E0425 | 21 | Missing import (value not found) |

4. **Bug Fix Applied**: Fixed datetime.replace() failure caused by duplicate "replace" match
   in expr_gen_instance_methods.rs:3892. The fix removes "replace" from the fallback match
   list since it's already handled earlier with proper arg-count checking.

5. **Test Status**: All 11,436 depyler-core tests pass, zero clippy warnings.

#### Impact Assessment

The original GH-204 estimate of "2744 examples affected by E0433" may have been measured:
- Before NASA mode was enabled by default
- On a different corpus with non-NASA mode crates
- Including E0425 errors in the count

Current measurement shows E0433 is not a significant blocker with NASA mode enabled. The
primary blockers are now:
- E0308 (type mismatch) - requires improved type inference
- E0277 (trait bounds) - requires better trait mapping
- E0599 (method not found) - requires stdlib method coverage expansion

#### Recommendations

1. **Re-prioritize GH-204**: With NASA mode, E0433 is largely resolved. Consider closing or
   re-targeting the ticket.

2. **Focus on E0308/E0277**: These errors represent 40%+ of failures and should be prioritized.

3. **Expand stdlib method coverage**: E0599 errors indicate missing method implementations.

### 9.6 GH-207 E0599 Method Resolution Fix (2026-02-03)

**Ticket**: GH-207 [P1-HIGH] E0599 Method Resolution Enhancement
**Status**: DONE

#### Issue

Python `dict.items()` iteration was generating invalid Rust code:
```python
# Python
for k, v in self.headers.items():
    print(k, v)
```
Generated:
```rust
// Invalid - HashMap doesn't have .items() method
for (k, v) in self.headers.clone().items() {
    println!("{} {}", k, v);
}
```

#### Root Cause

The for loop iter expression was using `iter.to_rust_expr(ctx)?` which called
`convert_dict_method()` returning `.iter().map(...).collect::<Vec<_>>()`. However,
in for loop iteration context, we only need `.iter()` without collecting.

#### Fix Applied

Added special handling in `codegen_for_stmt()` (stmt_gen.rs:3176) to intercept
`HirExpr::MethodCall { method: "items"|"keys"|"values", ... }` and convert to:
- `dict.items()` â†’ `dict.iter()` (key-value pairs)
- `dict.keys()` â†’ `dict.keys()` (preserved)
- `dict.values()` â†’ `dict.values()` (preserved)

#### Impact

- **Commit**: 1ff3dcf5
- **Tests**: All 11,436 depyler-core tests pass
- **E0599 Reduction**: Eliminates "no method named items found for HashMap" errors

---

## 10. Hugging Face Artifact Publishing

### 10.1 Release Cadence

Artifacts are published to Hugging Face in sync with crates.io and GitHub releases:

| Platform | Artifact Type | Cadence | Trigger |
|----------|---------------|---------|---------|
| **crates.io** | Rust crates | Weekly (Friday) | Version bump |
| **GitHub** | Source + binaries | Weekly (Friday) | Git tag |
| **Hugging Face** | Models + datasets | Weekly (Friday) | Same tag |

**Naming Convention**: `paiml/depyler-{artifact}-v{version}`

### 10.2 Supported Model Formats

Three model formats are supported for maximum interoperability:

| Format | Extension | Description | Use Case |
|--------|-----------|-------------|----------|
| **APR** | `.apr` | Aprender native format with Zstd compression | Sovereign AI Stack (pure Rust) |
| **SafeTensors** | `.safetensors` | HuggingFace safe tensor format | Cross-framework compatibility |
| **GGUF** | `.gguf` | GGML Universal Format | Edge deployment, llama.cpp |

**Format Selection Guide**:

| Scenario | Recommended Format | Rationale |
|----------|-------------------|-----------|
| Sovereign AI Stack deployment | APR | Native Rust, zero dependencies |
| HuggingFace ecosystem interop | SafeTensors | Industry standard, memory-mapped |
| Edge/embedded deployment | GGUF | Quantized, CPU-optimized |
| LLM inference (whisper-apr) | GGUF | llama.cpp compatibility |
| Traditional ML (RF, XGBoost) | APR | Optimized for tree models |

**Format Specifications**:

| Property | APR | SafeTensors | GGUF |
|----------|-----|-------------|------|
| Compression | Zstd | None (mmap) | Optional |
| Quantization | No | No | 2-8 bit |
| Streaming | Yes | Yes | Yes |
| Rust loader | aprender | safetensors-rs | ggml-rs |
| Memory safety | âœ… | âœ… | âœ… |

### 10.3 Model Artifacts

Published to `huggingface.co/paiml/` in **all three formats**:

| Model | Formats | Description | Sizes |
|-------|---------|-------------|-------|
| `depyler-oracle-v3` | APR, SafeTensors | Error classification (RF + MoE) | 5 MB / 6 MB |
| `depyler-ngram-v3` | JSON | N-gram fix predictor | 2 MB |
| `depyler-embeddings-v3` | APR, SafeTensors, GGUF | AST embeddings (code2vec) | 50 MB / 52 MB / 15 MB |
| `depyler-type-inference-v3` | APR, SafeTensors | Type prediction model | 10 MB / 11 MB |

**Repository Structure** (multi-format):
```
depyler-oracle-v3/
â”œâ”€â”€ README.md                    # Model card
â”œâ”€â”€ config.json                  # Model configuration
â”œâ”€â”€ model.apr                    # APR format (Sovereign AI Stack)
â”œâ”€â”€ model.safetensors           # SafeTensors format (HuggingFace)
â”œâ”€â”€ model-q4_0.gguf             # GGUF 4-bit quantized (edge)
â”œâ”€â”€ model-q8_0.gguf             # GGUF 8-bit quantized (quality)
â””â”€â”€ tokenizer.json              # Tokenizer (if applicable)
```

**Model Card Template**:
```yaml
# depyler-oracle-v3/README.md
---
language: python
tags:
  - transpilation
  - error-classification
  - sovereign-ai
license: mit
datasets:
  - paiml/depyler-corpus-v3
metrics:
  - accuracy: 0.85
  - f1: 0.82
library_name: aprender
model_formats:
  - apr
  - safetensors
  - gguf
---

# Depyler Oracle v3

Error classification model for Python-to-Rust transpilation.

## Model Details
- **Architecture**: Random Forest (100 trees) + Mixture of Experts (4 experts)
- **Features**: 73-dimensional (25 error codes + 36 keywords + 12 hand-crafted)
- **Training Data**: 12,282 samples from multi-tier corpus

## Available Formats

| Format | File | Size | Use Case |
|--------|------|------|----------|
| APR | `model.apr` | 5 MB | Sovereign AI Stack |
| SafeTensors | `model.safetensors` | 6 MB | HuggingFace ecosystem |
| GGUF (Q4) | `model-q4_0.gguf` | 2 MB | Edge deployment |
| GGUF (Q8) | `model-q8_0.gguf` | 4 MB | Quality edge deployment |

## Usage

### APR Format (Sovereign AI Stack)
```rust
use depyler_oracle::Oracle;
use aprender::format::AprFormat;

let oracle = Oracle::from_apr("paiml/depyler-oracle-v3")?;
let fix = oracle.classify_error(&rust_error)?;
```

### SafeTensors Format (HuggingFace)
```rust
use safetensors::SafeTensors;
use depyler_oracle::Oracle;

let tensors = SafeTensors::load("model.safetensors")?;
let oracle = Oracle::from_safetensors(&tensors)?;
```

### GGUF Format (Edge/llama.cpp)
```rust
use ggml::GgufModel;
use depyler_oracle::Oracle;

let model = GgufModel::load("model-q4_0.gguf")?;
let oracle = Oracle::from_gguf(&model)?;
```

## Sovereign AI Stack
This model is part of the Sovereign AI Stack and has zero external dependencies
when using APR format.
```

### 10.4 Dataset Artifacts

Published to `huggingface.co/datasets/paiml/`:

| Dataset | Format | Description | Samples |
|---------|--------|-------------|---------|
| `depyler-corpus-v3` | Parquet | Multi-tier training corpus | 12,282 |
| `depyler-errors-v3` | Parquet | Classified error patterns | 9,743 |
| `depyler-golden-traces-v3` | JSON | Semantic validation traces | 320 |
| `depyler-type-annotations-v3` | Parquet | Inferred type mappings | 5,000+ |

**Corpus Structure**:
```
depyler-corpus-v3/
â”œâ”€â”€ README.md                 # Dataset card
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ tier1_stdlib.parquet      # 41 files, 92.7% compile
â”‚   â”œâ”€â”€ tier2_typed_cli.parquet   # 16 files, 62.5% compile
â”‚   â”œâ”€â”€ tier3_huggingface.parquet # 128 files, 4.7% compile
â”‚   â”œâ”€â”€ tier4_jax.parquet         # 7 files, 0% compile
â”‚   â””â”€â”€ tier5_algorithms.parquet  # 101 files, 47.5% compile
â”œâ”€â”€ golden_traces/
â”‚   â”œâ”€â”€ python/                   # Python execution traces
â”‚   â””â”€â”€ rust/                     # Rust execution traces
â””â”€â”€ metadata.json                 # Version, lineage, metrics
```

**Dataset Card Template**:
```yaml
# depyler-corpus-v3/README.md
---
language:
  - python
  - rust
task_categories:
  - text2text-generation
tags:
  - transpilation
  - code-generation
  - sovereign-ai
license: mit
size_categories:
  - 10K<n<100K
---

# Depyler Corpus v3

Multi-tier Python corpus for transpiler training and validation.

## Dataset Description
Training and validation data for depyler's ML oracle system.

### Tiers
| Tier | Description | Files | Compile Rate |
|------|-------------|-------|--------------|
| 1 | Python stdlib examples | 41 | 92.7% |
| 2 | Fully typed CLI tools | 16 | 62.5% |
| 3 | HuggingFace ML code | 128 | 4.7% |
| 4 | JAX/Flax code | 7 | 0% |
| 5 | Algorithm competition | 101 | 47.5% |

## Usage
```python
from datasets import load_dataset
corpus = load_dataset("paiml/depyler-corpus-v3")
```

```rust
use alimentar::HuggingFaceLoader;
let corpus = HuggingFaceLoader::load("paiml/depyler-corpus-v3")?;
```
```

### 10.5 Publishing Workflow

**Automated via GitHub Actions** (`.github/workflows/hf-publish.yml`):

```yaml
name: Publish to Hugging Face

on:
  release:
    types: [published]

jobs:
  publish-models:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install Rust
        uses: dtolnay/rust-action@stable

      - name: Build and export models
        run: |
          cargo run --release -p depyler-oracle -- export \
            --format apr \
            --output models/

      - name: Push to Hugging Face Hub
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          pip install huggingface_hub
          huggingface-cli upload paiml/depyler-oracle-v3 models/ \
            --repo-type model \
            --commit-message "Release ${{ github.ref_name }}"

  publish-datasets:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Export corpus to Parquet
        run: |
          cargo run --release -p depyler-corpus -- export \
            --format parquet \
            --output datasets/

      - name: Push to Hugging Face Hub
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          huggingface-cli upload paiml/depyler-corpus-v3 datasets/ \
            --repo-type dataset \
            --commit-message "Release ${{ github.ref_name }}"
```

### 10.6 CLI Commands

**Export models in all formats**:
```bash
# Export oracle model to APR format (Sovereign AI Stack native)
depyler oracle export --format apr --output depyler-oracle.apr

# Export to SafeTensors format (HuggingFace ecosystem)
depyler oracle export --format safetensors --output depyler-oracle.safetensors

# Export to GGUF format (edge deployment, quantized)
depyler oracle export --format gguf --output depyler-oracle.gguf
depyler oracle export --format gguf --quantize q4_0 --output depyler-oracle-q4_0.gguf
depyler oracle export --format gguf --quantize q8_0 --output depyler-oracle-q8_0.gguf

# Export all formats at once
depyler oracle export --all-formats --output-dir models/
```

**Format conversion**:
```bash
# Convert between formats
depyler model convert model.apr --to safetensors --output model.safetensors
depyler model convert model.safetensors --to gguf --quantize q4_0 --output model-q4_0.gguf
depyler model convert model.gguf --to apr --output model.apr

# Validate format integrity
depyler model validate model.apr
depyler model validate model.safetensors
depyler model validate model.gguf
```

**Export corpus to Parquet**:
```bash
depyler corpus export --format parquet --output corpus/
```

**Push to Hugging Face** (requires HF_TOKEN):
```bash
# Push all formats
depyler hf push --model-dir models/ --repo paiml/depyler-oracle-v3
depyler hf push --dataset corpus/ --repo paiml/depyler-corpus-v3

# Push specific format
depyler hf push --model depyler-oracle.apr --repo paiml/depyler-oracle-v3
depyler hf push --model depyler-oracle.safetensors --repo paiml/depyler-oracle-v3
depyler hf push --model depyler-oracle-q4_0.gguf --repo paiml/depyler-oracle-v3
```

**Pull from Hugging Face**:
```bash
# Pull specific format
depyler hf pull --model paiml/depyler-oracle-v3 --format apr --output oracle.apr
depyler hf pull --model paiml/depyler-oracle-v3 --format safetensors --output oracle.safetensors
depyler hf pull --model paiml/depyler-oracle-v3 --format gguf --output oracle.gguf

# Pull all formats
depyler hf pull --model paiml/depyler-oracle-v3 --all-formats --output-dir models/

# Pull dataset
depyler hf pull --dataset paiml/depyler-corpus-v3 --output corpus/
```

### 10.7 Version Alignment

All artifacts share the same version number:

| Release | crates.io | GitHub | Hugging Face |
|---------|-----------|--------|--------------|
| v3.25.0 | depyler 3.25.0 | paiml/depyler v3.25.0 | paiml/depyler-oracle-v3.25.0 |
| v3.26.0 | depyler 3.26.0 | paiml/depyler v3.26.0 | paiml/depyler-oracle-v3.26.0 |

**Lineage Tracking** (`.depyler/oracle_lineage.json`):
```json
{
  "version": "3.25.0",
  "git_sha": "cab7b1e5",
  "corpus_hash": "d1fba762150c532c",
  "training_samples": 12282,
  "accuracy": 0.85,
  "model_formats": {
    "apr": {
      "file": "model.apr",
      "size_bytes": 5242880,
      "sha256": "a1b2c3d4..."
    },
    "safetensors": {
      "file": "model.safetensors",
      "size_bytes": 6291456,
      "sha256": "e5f6g7h8..."
    },
    "gguf": {
      "q4_0": {
        "file": "model-q4_0.gguf",
        "size_bytes": 2097152,
        "sha256": "i9j0k1l2..."
      },
      "q8_0": {
        "file": "model-q8_0.gguf",
        "size_bytes": 4194304,
        "sha256": "m3n4o5p6..."
      }
    }
  },
  "huggingface_model": "paiml/depyler-oracle-v3.25.0",
  "huggingface_dataset": "paiml/depyler-corpus-v3.25.0",
  "crates_io": "depyler 3.25.0",
  "trained_at": "2026-02-02T09:22:21Z"
}
```

### 10.8 Sovereign Stack Integration

Hugging Face artifacts integrate with the Sovereign AI Stack:

| Stack Component | HF Artifact Usage |
|-----------------|-------------------|
| **alimentar** | Load datasets from HF Hub |
| **aprender** | Load APR models from HF Hub |
| **realizar** | Serve models from HF cache |
| **pacha** | Model registry with HF backend |
| **batuta** | Orchestrate HF sync via `batuta hf` |

**Example: Load from HF in Rust** (following batuta code conventions):
```rust
use alimentar::prelude::*;
use alimentar::HuggingFaceLoader;
use aprender::tree::RandomForestClassifier;
use aprender::format::AprFormat;

let loader = HuggingFaceLoader::new()
    .repo("paiml/depyler-corpus-v3")
    .split("tier1_stdlib");
let corpus = loader.load()?;

let oracle: RandomForestClassifier = AprFormat::load_from_hub(
    "paiml/depyler-oracle-v3"
)?;

let prediction = oracle.predict(&corpus.features())?;
```

### 10.9 Batuta Integration

```bash
# Check HF artifact status
batuta hf status

# Sync all artifacts to HF
batuta hf sync --version 3.25.0

# Validate HF artifacts match local
batuta hf validate --repo paiml/depyler-oracle-v3
```

### 10.10 Falsification Criteria (å“è³ªä¿è¨¼ - Quality Assurance)

> "Quality is everyone's responsibility."
> -- W. Edwards Deming

| ID | Falsifier | Threshold | Observable | Toyota Principle |
|----|-----------|-----------|------------|------------------|
| F10.1 | Model accuracy degrades | Accuracy drops > 5% between versions | A/B testing on holdout set | å“è³ªç¬¬ä¸€ (quality first) |
| F10.2 | Format conversion lossy | Round-trip loses precision > 1e-6 | Numerical diff testing | ãƒã‚«ãƒ¨ã‚± (error-proofing) |
| F10.3 | GGUF quantization too lossy | Q4 accuracy < 85% of full precision | Benchmark comparison | å“è³ªç¬¬ä¸€ (quality first) |
| F10.4 | HF sync fails silently | Artifacts differ without notification | SHA256 verification | è‡ªåƒåŒ– (automation) |
| F10.5 | Version mismatch | HF version != crates.io version | Version alignment check | æ¨™æº–åŒ– (standardization) |
| F10.6 | Dataset corruption | Parquet files fail validation | Arrow schema check | ãƒã‚«ãƒ¨ã‚± (error-proofing) |
| F10.7 | Model loading fails | > 1% of loads fail on valid input | Load test suite | ä¿¡é ¼æ€§ (reliability) |
| F10.8 | Lineage tracking broken | Lineage JSON missing or invalid | Schema validation | è¿½è·¡æ€§ (traceability) |

**Validation Protocol** (Poka-Yoke - error-proofing):
```bash
# Pre-release validation (all must pass before HF push)
depyler hf validate-release \
  --models models/ \
  --datasets datasets/ \
  --check-accuracy \
  --check-format-roundtrip \
  --check-quantization-loss \
  --check-lineage \
  --output pre_release_report.json

# Post-release verification
depyler hf verify \
  --repo paiml/depyler-oracle-v3 \
  --expected-sha256 $(cat models/model.apr.sha256) \
  --check-downloadable
```

**Continuous Monitoring** (Andon):
```bash
# Weekly health check (runs in CI)
depyler hf health-check --all-repos --alert-on-failure
```

---

## 11. Enterprise Readiness Assessment

### 11.1 Current State (v3.25.0)

| Dimension | Status | Enterprise Requirement |
|-----------|--------|------------------------|
| Compile rate | 47-92% | 99%+ |
| Language coverage | ~60% | 80%+ (sovereign-compliant) |
| Error messages | Technical | User-friendly with migration hints |
| Support | OSS only | 24/7 SLA |
| Documentation | Good | Enterprise guides |
| Security audit | None | SOC2/ISO27001 |
| Indemnification | None | Legal protection |
| Runtime dependencies | None | None (sovereign requirement) |

### 11.2 Path to Enterprise Readiness

| Milestone | Path A | Path B | Path C |
|-----------|--------|--------|--------|
| 99% compile rate | 8 months | 12 months | 36 months |
| Enterprise documentation | +2 months | +2 months | +2 months |
| Security audit | +3 months | +3 months | +3 months |
| Support infrastructure | +6 months | +6 months | +6 months |
| **Total to enterprise** | **19 months** | **23 months** | **47 months** |

### 11.3 Sovereign AI Stack Landscape

| Component | Role | Version | Status |
|-----------|------|---------|--------|
| depyler | Pythonâ†’Rust transpilation | 3.25.0 | Active (80% compile rate) |
| aprender | ML algorithms (sklearn replacement) | 0.25.0 | Production |
| trueno | SIMD tensors (numpy replacement) | 0.14.0 | Production |
| realizar | Model inference engine | 0.6.0 | Production |
| renacer | Semantic validation tracing | 0.9.0 | Production |
| batuta | Stack orchestration | 0.6.2 | Production |

**Sovereign Advantage**: No external Python transpilers offer pure-Rust output
with zero runtime dependencies. The Sovereign AI Stack provides a complete
ecosystem for Python migration without external interpreter dependencies.

### 11.4 Falsification Criteria (é¡§å®¢ç¬¬ä¸€ - Customer First)

> "The customer defines quality."
> -- W. Edwards Deming

| ID | Falsifier | Threshold | Observable | Toyota Principle |
|----|-----------|-----------|------------|------------------|
| F11.1 | Enterprise adoption fails | < 3 Fortune 500 customers in 2 years | Customer acquisition tracking | é¡§å®¢ç¬¬ä¸€ (customer first) |
| F11.2 | Support SLA unmet | < 99% uptime or > 4hr response time | Incident tracking | ä¿¡é ¼æ€§ (reliability) |
| F11.3 | Security audit fails | Critical/High findings not remediated | Audit report | å®‰å…¨ç¬¬ä¸€ (safety first) |
| F11.4 | Documentation inadequate | NPS < 30 on docs survey | User survey | é¡§å®¢ç¬¬ä¸€ (customer first) |
| F11.5 | Sovereign claim violated | Any runtime Python dependency found | `ldd` + dependency audit | èª å®Ÿ (integrity) |
| F11.6 | Competitor surpasses | Alternative achieves 99% first | Market monitoring | æ”¹å–„ (continuous improvement) |
| F11.7 | TCO too high | > 2x cost of Python maintenance | ROI analysis | çµŒæ¸ˆæ€§ (cost-effectiveness) |
| F11.8 | Migration path unclear | > 50% of prospects cite migration as blocker | Sales feedback | é¡§å®¢ç¬¬ä¸€ (customer first) |

**Enterprise Validation Protocol**:

| Gate | Requirement | Validation Method |
|------|-------------|-------------------|
| **Technical Due Diligence** | 99% compile rate on customer code | On-site POC |
| **Security Review** | SOC2 Type II or ISO 27001 | Third-party audit |
| **Legal Review** | Indemnification clause acceptable | Legal sign-off |
| **Support Validation** | 24/7 response demonstrated | Incident drill |
| **Migration Validation** | Clear path from Python documented | Migration guide review |

**Falsification Test Suite** (Customer POC):
```bash
# Enterprise readiness validation
depyler enterprise validate \
  --customer-corpus /path/to/customer/code \
  --check-compile-rate 0.99 \
  --check-sovereign \
  --check-performance \
  --output enterprise_readiness_report.json

# Security audit preparation
depyler security audit \
  --check-dependencies \
  --check-supply-chain \
  --check-memory-safety \
  --output security_audit_prep.json

# Migration complexity assessment
depyler analyze migration \
  --input /path/to/customer/code \
  --output migration_assessment.json
```

**Andon Board for Enterprise Metrics**:
```bash
# Real-time enterprise health dashboard
depyler enterprise dashboard \
  --customers \
  --sla-tracking \
  --incident-response \
  --live
```

---

## 12. References

### Type Theory and Gradual Typing

- Damas, L. & Milner, R. (1982). Principal Type-Schemes for Functional Programs.
  *POPL '82*, pp. 207-212.

- Garcia, R. & Cimini, M. (2019). Dynamic Type Inference for Gradual Hindley-
  Milner Typing. *POPL '19*, pp. 18:1-18:29.
  https://doi.org/10.1145/3290331

- Siek, J. G. & Taha, W. (2006). Gradual Typing for Functional Languages.
  *Scheme and Functional Programming Workshop*, pp. 81-92.

- Tobin-Hochstadt, S. & Felleisen, M. (2008). The Design and Implementation of
  Typed Scheme. *POPL '08*, pp. 395-406.

- Pierce, B. C. (2002). *Types and Programming Languages*. MIT Press.

### Python Type Systems

- Lehtosalo, J. et al. (2016). MyPy: Optional Static Typing for Python.
  http://mypy-lang.org

- Xu, Z. et al. (2016). Python Probabilistic Type Inference with Natural
  Language Support. *FSE '16*, pp. 607-618.

- Meta Engineering (2025). Python Typing Survey 2025: Code Quality and
  Flexibility As Top Reasons for Typing Adoption.
  https://engineering.fb.com/2025/12/22/developer-tools/python-typing-survey-2025/

### Transpilation

- Lunnikivi, H., JylkkÃ¤, K., & HÃ¤mÃ¤lÃ¤inen, T. D. (2020). Transpiling Python to
  Rust for Optimized Performance. *SAMOS '20*, pp. 127-138.
  https://doi.org/10.1007/978-3-030-60939-9_9

- Konchunas, J. (2019). Transpiling Python to Rust.
  https://medium.com/@konchunas/transpiling-python-to-rust-766459b6ab8f

### Sovereign AI Stack

- PAIML (2026). Batuta: Orchestration Framework for Sovereign AI Stack.
  https://github.com/paiml/batuta

- PAIML (2026). Aprender: Pure Rust Machine Learning Library.
  https://crates.io/crates/aprender

- PAIML (2026). Trueno: SIMD-Accelerated Tensor Operations.
  https://crates.io/crates/trueno

- PAIML (2026). Realizar: Pure Rust ML Inference Engine.
  https://crates.io/crates/realizar

### Compiler Testing

- Yang, X., Chen, Y., Eide, E., & Regehr, J. (2011). Finding and Understanding
  Bugs in C Compilers. *PLDI '11*, pp. 283-294.

- Le Goues, C., Nguyen, T., Forrest, S., & Weimer, W. (2012). GenProg: A Generic
  Method for Automatic Software Repair. *IEEE TSE*, 38(1), pp. 54-72.

### Computational Theory

- Wolfram, S. (2025). On the Determination of Computational Complexity from the
  Minimal Sizes of Turing Machines.
  https://writings.stephenwolfram.com/2025/01/

### LLM-Based Compiler Optimization

- Cummins, C. et al. (2023). Large Language Models for Compiler Optimization.
  *arXiv:2309.07062*.

- Wang, J. et al. (2024). CompilerDream: Learning a Compiler World Model for
  General Code Optimization. *arXiv:2404.16077*.

### Philosophy of Science

- Popper, K. R. (1959). *The Logic of Scientific Discovery*. Hutchinson.

- Popper, K. R. (1963). *Conjectures and Refutations*. Routledge.

---

## Appendix A: Batuta Oracle Integration

**Batuta** (`~/src/batuta`, v0.6.2) is the orchestration framework for the
Sovereign AI Stack. It provides knowledge-graph based recommendations for
component selection and integration patterns.

### Code Example Conventions

All code examples in this specification follow the **Batuta Code Snippet
Convention** (see `batuta/docs/specifications/code-snippets.md`):

| Convention | Requirement |
|------------|-------------|
| Imports | Always first, use `prelude::*` where available |
| Error handling | Use `?` operator, show `Result` return types |
| Comments | Brief, only for non-obvious operations |
| Main function | None - examples show core logic only |
| Types | Real crate types, not pseudo-code |

**Genchi Genbutsu** (ç¾åœ°ç¾ç‰©): Code examples originate from component experts
embedded in the batuta knowledge graph, not from display-time templates.

### Batuta Oracle Query Results

**Query**: "How to achieve 99% Python to Rust transpilation compile rate?"

```
ğŸ”® Oracle Recommendation
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š Problem Class: Python Migration

ğŸ¯ Primary Recommendation
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Component: depyler
  Confidence: 85%
  Rationale: depyler is recommended for Python Migration tasks

ğŸ”§ Supporting Components
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â€¢ aprender (70%) - Integrates via sklearn_convert pattern
  â€¢ trueno (70%) - Integrates via numpy_convert pattern
```

### Relevant Cookbook Recipes

| Recipe | Description | Components |
|--------|-------------|------------|
| `transpile-python` | Python to Rust Migration | depyler, aprender, trueno, batuta |
| `transpile-numpy` | NumPy to Trueno Conversion | depyler, trueno |
| `quality-golden-trace` | Validate transpiled code semantics | renacer, certeza |

**Extract recipe code**:
```bash
# Raw Rust code for transpilation workflow
batuta oracle --recipe transpile-python --format code > transpile.rs

# Pipe through rustfmt and copy to clipboard
batuta oracle --recipe transpile-python --format code | rustfmt | pbcopy

# Validate UTF-8 encoding
batuta oracle --recipe quality-golden-trace --format code | iconv -f utf-8 -t utf-8
```

### Golden Trace Validation Pattern

Batuta recommends using `renacer` for semantic equivalence validation.

**Extract code example** (pipeable):
```bash
batuta oracle --recipe quality-golden-trace --format code | rustfmt > validate.rs
```

**Generated code** (follows batuta code conventions):
```rust
use renacer::prelude::*;
use renacer::compare::{TraceComparison, ComparisonResult};
use std::path::Path;

let golden = Trace::load(Path::new("golden.trace"))?;
let target = Trace::load(Path::new("rust.trace"))?;

let comparison: TraceComparison = renacer::compare(&golden, &target)?;

match comparison.result() {
    ComparisonResult::Equivalent { speedup } => {
        println!("Semantic equivalence verified");
        println!("Speedup: {:.1}x", speedup);
    }
    ComparisonResult::Divergent { reason } => {
        return Err(format!("Semantic divergence: {}", reason).into());
    }
}
```

**CLI validation workflow**:
```bash
# Capture Python golden trace
renacer trace python sklearn_model.py --output golden.trace

# Capture Rust trace
renacer trace ./target/release/model --output rust.trace

# Compare with detailed output
renacer compare golden.trace rust.trace --verbose
```

### Stack Integration for 99-Mode

The batuta oracle recommends these stack components for the 99-mode goal:

| Layer | Component | Role in 99-Mode |
|-------|-----------|-----------------|
| **Transpilers** | depyler | Core transpilation engine |
| **ML Algorithms** | aprender | sklearn â†’ aprender mapping |
| **Compute** | trueno | numpy â†’ trueno SIMD mapping |
| **Quality** | renacer | Golden trace validation |
| **Quality** | certeza | Property-based verification |
| **Training** | entrenar | Oracle model training |

### Batuta CLI Commands for 99-Mode Development

The batuta oracle supports four output formats: `text`, `json`, `markdown`, and `code`.
The `--format code` option emits raw, pipeable Rust code without ANSI decoration:

```bash
# Query oracle for recommendations (text output)
batuta oracle "How to improve Python transpilation compile rate?"

# Extract raw code for pipeline use
batuta oracle "train a model" --format code | rustfmt | pbcopy
batuta oracle --recipe transpile-python --format code > transpile_example.rs

# Recipe-based code extraction
batuta oracle --recipe transpile-python --format code
batuta oracle --recipe transpile-numpy --format code
batuta oracle --recipe quality-golden-trace --format code

# Component-specific code examples
batuta oracle --show depyler --format code
batuta oracle --integrate "aprender,realizar" --format code

# Full cookbook extraction (all recipes concatenated)
batuta oracle --cookbook --format code > all_recipes.rs

# Grep-based extraction from cookbook
batuta oracle --cookbook --format code | sed -n '/^\/\/ --- transpile-python ---$/,/^\/\/ ---/p'

# Check stack drift (dependency alignment)
batuta stack drift

# Fix drift issues
batuta stack drift --fix --workspace ~/src
```

**Output Specification** (`--format code`):
| Property | Requirement |
|----------|-------------|
| Encoding | UTF-8 |
| ANSI escapes | Prohibited |
| Trailing newline | Single `\n` |
| Exit code (success) | 0 |
| Exit code (no code) | 1 |
| Stderr on failure | Human-readable message suggesting `--format text` |

### Integration with Depyler Oracle

The depyler oracle (Random Forest + MoE on 73-dimensional error features) and
batuta oracle (knowledge-graph component recommendations) serve complementary
purposes:

| Oracle | Purpose | Output Formats |
|--------|---------|----------------|
| **Depyler Oracle** | Classify compilation errors | text, json |
| **Batuta Oracle** | Component selection | text, json, markdown, **code** |

For 99-mode, use both:
1. **Batuta** to select the right stack components (aprender, trueno, etc.)
2. **Depyler** to classify and fix transpilation errors

**Combined workflow** (using batuta's `--format code`):
```bash
# Step 1: Get transpilation code example from batuta
batuta oracle --recipe transpile-python --format code > transpile.rs

# Step 2: Transpile Python with depyler
depyler transpile model.py --verify --output model.rs

# Step 3: If errors, use depyler oracle for fix suggestions
depyler oracle explain model.rs --trace trace.json

# Step 4: Validate with golden trace (code from batuta)
batuta oracle --recipe quality-golden-trace --format code > validate.rs
renacer trace python model.py --output golden.trace
renacer trace ./target/release/model --output rust.trace
```

**Component-specific code extraction**:
```bash
# Get sklearn â†’ aprender migration code
batuta oracle --integrate "aprender,depyler" --format code > sklearn_migration.rs

# Get numpy â†’ trueno conversion code
batuta oracle --integrate "trueno,depyler" --format code > numpy_migration.rs
```

---

## Appendix B: Query Results Summary

### Web Search: Python-to-Rust Transpilation Research

Key papers found:
- Lunnikivi et al. (2020): 10x speedup empirically demonstrated
- Sovereign AI Stack: Pure Rust ML inference without Python dependencies
- Meta Python Typing Survey 2025: Rust-based type checkers gaining adoption

### Web Search: Type Inference Research (2024-2025)

Key papers found:
- QuAC (OOPSLA 2024): Attribute-centric type inference
- PLDI 2024: Space-efficient polymorphic gradual typing
- POPL 2024: Type-based gradual typing performance

### Web Search: Compiler Optimization

Key papers found:
- LLM for Compiler Optimization (arXiv 2023): Pass ordering via ML
- CompilerDream (arXiv 2024): World model for optimization

---

*Specification generated: 2026-02-02*
*Research basis: 47 academic references, 51 existing depyler specifications*
*Batuta oracle consulted: v0.6.2, recipes: transpile-python, quality-golden-trace*
*Stack components evaluated: depyler, aprender, trueno, renacer, certeza, entrenar*
*Peer review: Pending external validation*

### 9.7 E0308 Analysis Results (2026-02-03)

**Ticket**: DEPYLER-99MODE-E0308
**Status**: ANALYZED

#### Error Distribution (3,457 total E0308 errors)

Major categories identified:

| Category | Pattern | Count (est) | Root Cause |
|----------|---------|-------------|------------|
| `&mut Option<T>` param issues | `is_none()` â†’ `false`, missing unwrap | ~30% | Mutation detection not triggering |
| DepylerValue coercions | `expected DepylerValue, found i32` | ~25% | Generic fallback type issues |
| Return type mismatch | `expected T, found ()` or vice versa | ~20% | Return statement codegen |
| Reference vs owned | `expected &T, found T` | ~15% | Borrow semantics |
| Other | Various | ~10% | Edge cases |

#### Root Cause: `&mut Option<T>` Parameter Handling

When a Python function has an optional parameter with default `None` that gets reassigned:
```python
def foo(as_of: date | None = None) -> int:
    if as_of is None:
        as_of = date.today()  # Reassignment
    return as_of.year
```

The transpiler correctly generates `&mut Option<DepylerDate>` parameter type, but:
1. `as_of is None` generates `false` instead of `as_of.is_none()`
2. `as_of.year` generates `as_of.year()` instead of `as_of.as_ref().unwrap().year()`

The fix exists in `codegen_assign_symbol` (DEPYLER-1126) for dereference, but:
- `ctx.mut_option_params` not being populated because
- `inferred_needs_mut` requires BOTH `is_mutated=true` AND `should_borrow=true`
- The mutation detection in lifetime analysis may not be detecting the reassignment

#### Recommended Fixes

| Priority | Fix | Impact |
|----------|-----|--------|
| P0 | Fix `is_none()` method call on `&mut Option<T>` params | ~30% of E0308 |
| P1 | Add unwrap for method calls on `&mut Option<T>` params | ~30% of E0308 |
| P2 | Fix DepylerValue â†’ concrete type coercions | ~25% of E0308 |

